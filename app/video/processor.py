"""
–ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∏–¥–µ–æ —Å MediaPipe + BoulderVision

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:
- MediaPipe Pose –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–∫–µ–ª–µ—Ç–∞
- BoulderVision –º–µ—Ç—Ä–∏–∫–∏ (Velocity Ratio, Cumulative Distance)
- Roboflow –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∑–∞—Ü–µ–ø–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- 8 —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
"""

import cv2
import mediapipe as mp
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
import numpy as np
import math

from app.config import (
    MEDIAPIPE_MODEL_COMPLEXITY, 
    FRAME_SKIP, 
    TEMP_DIR,
    ROBOFLOW_API_KEY,
    ROBOFLOW_PROJECT,
    ROBOFLOW_MODEL_VERSION,
    BOULDERVISION_BUFFER_SIZE,
    ENABLE_HOLD_DETECTION
)
from app.analysis import (
    FrameAnalyzer,
    FallDetector,
    generate_csv_report,
    BodyTensionAnalyzer,
    InjuryPredictor,
    ClimberNineBoxModel,
    RouteAssessor
)
from app.analysis.csv_generator import analyze_technical_issues
from app.bouldervision import BoulderVisionMetrics, HoldsDetector
from .overlays import VideoOverlays

logger = logging.getLogger(__name__)


class VideoProcessor:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–∏–¥–µ–æ —Å MediaPipe + BoulderVision
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 8 —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:
    
    –ë–∞–∑–æ–≤—ã–µ (5):
    - skeleton: —Å–∫–µ–ª–µ—Ç —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏
    - points: –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
    - stress: —Ç–æ—á–∫–∏ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è (–ø–æ —É–≥–ª–∞–º —Å—É—Å—Ç–∞–≤–æ–≤)
    - center: —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å –∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è
    - metrics: –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ
    
    BoulderVision (3):
    - heatmap: —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –ø–æ–∑–∏—Ü–∏–π
    - trajectory: –ø–æ–ª–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏—è
    - holds: –∑–∞—Ü–µ–ø—ã + —Å–∫–µ–ª–µ—Ç + —Å–≤—è–∑–∏
    
    –í–ê–ñ–ù–û: –í—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Å–æ–∑–¥–∞—é—Ç—Å—è –í–ù–£–¢–†–ò process_video()
    –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–∑–∞—â–∏—Ç–∞ –æ—Ç race condition)
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ MediaPipe Pose (–±–µ–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è)"""
        self.mp_pose = mp.solutions.pose
        logger.info("‚úÖ VideoProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (stateless)")
    
    async def process_video(
        self,
        video_path: Path,
        output_overlay: str = "skeleton",
        progress_callback=None
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑
        
        Args:
            video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
            output_overlay: —Ç–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (8 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
            progress_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤–∫–ª—é—á–∞—è BoulderVision –º–µ—Ç—Ä–∏–∫–∏
        """
        # –ò–ó–û–õ–Ø–¶–ò–Ø –°–û–°–¢–û–Ø–ù–ò–Ø: —Å–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç race condition –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
        pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=MEDIAPIPE_MODEL_COMPLEXITY,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        frame_analyzer = FrameAnalyzer()
        fall_detector = FallDetector()
        overlays = VideoOverlays()
        bv_metrics = BoulderVisionMetrics(buffer_size=BOULDERVISION_BUFFER_SIZE)
        tension_analyzer = BodyTensionAnalyzer()
        injury_predictor = InjuryPredictor()
        nine_box_model = ClimberNineBoxModel()
        route_assessor = RouteAssessor()
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        from app.analysis.technique_metrics import TechniqueMetricsAnalyzer
        from app.analysis.additional_metrics import AdditionalMetricsAnalyzer
        from app.analysis.swot_generator import SWOTGenerator
        
        technique_analyzer = TechniqueMetricsAnalyzer()
        additional_analyzer = AdditionalMetricsAnalyzer()
        swot_generator = SWOTGenerator()
        
        # –î–µ—Ç–µ–∫—Ç–æ—Ä –∑–∞—Ü–µ–ø–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        holds_detector: Optional[HoldsDetector] = None
        if ENABLE_HOLD_DETECTION and ROBOFLOW_API_KEY and output_overlay == "holds":
            try:
                holds_detector = HoldsDetector(
                    api_key=ROBOFLOW_API_KEY,
                    project_name=ROBOFLOW_PROJECT,
                    model_version=ROBOFLOW_MODEL_VERSION
                )
                logger.info("‚úÖ HoldsDetector —Å–æ–∑–¥–∞–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å HoldsDetector: {e}")
                holds_detector = None
        
        cap = None
        out = None
        output_path = None
        
        try:
            logger.info(f"üé¨ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {video_path}")
            logger.info(f"üìä –¢–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {output_overlay}")
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
            cap = cv2.VideoCapture(str(video_path))
            
            if not cap.isOpened():
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
            
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0
            
            logger.info(f"üìπ –í–∏–¥–µ–æ: {width}x{height}, {fps} FPS, {total_frames} –∫–∞–¥—Ä–æ–≤, {duration:.1f}—Å")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            output_path = TEMP_DIR / f"processed_{video_path.stem}.mp4"
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
            
            frame_number = 0
            processed_count = 0
            
            # –î–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∑–∞—Ü–µ–ø–æ–≤ (–∫—ç—à–∏—Ä—É–µ–º –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ)
            detected_holds: List = []
            holds_detection_interval = 30  # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –∑–∞—Ü–µ–ø—ã –∫–∞–∂–¥—ã–µ N –∫–∞–¥—Ä–æ–≤
            
            # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ (–ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            bv_metrics.reset()
            tension_analyzer.reset()
            if holds_detector:
                holds_detector.reset()
            overlays.reset()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
            while cap.isOpened():
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                timestamp = frame_number / fps if fps > 0 else 0
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if frame_number % FRAME_SKIP == 0:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –¥–ª—è MediaPipe
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–∑—ã
                    results = pose.process(frame_rgb)
                    
                    # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–∞
                    frame_data = frame_analyzer.analyze_frame(
                        frame_number,
                        results.pose_landmarks,
                        timestamp
                    )
                    
                    # BoulderVision: –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –¥–≤–∏–∂–µ–Ω–∏—è
                    bv_frame_metrics = bv_metrics.process_frame(
                        results.pose_landmarks,
                        frame_number,
                        timestamp
                    )
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º BV –º–µ—Ç—Ä–∏–∫–∏ –≤ frame_data
                    frame_data.update({
                        'velocity_ratio': bv_frame_metrics.get('velocity_ratio', 1.0),
                        'cumulative_distance': bv_frame_metrics.get('cumulative_distance', 0.0),
                        'current_velocity': bv_frame_metrics.get('current_velocity', 0.0)
                    })
                    
                    # –î–µ—Ç–µ–∫—Ü–∏—è –∑–∞—Ü–µ–ø–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –∏ —ç—Ç–æ –Ω—É–∂–Ω—ã–π overlay)
                    if holds_detector and output_overlay == "holds":
                        if frame_number % holds_detection_interval == 0:
                            detected_holds = holds_detector.detect_holds(
                                frame, frame_number
                            )
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∑–∞—Ü–µ–ø–∞–º–∏
                        if detected_holds:
                            holds_detector.update_interactions(
                                results.pose_landmarks,
                                detected_holds,
                                frame_number
                            )
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–∞–¥–µ–Ω–∏–µ
                    fall_info = fall_detector.check_fall(
                        frame_data,
                        frame_analyzer.frame_data
                    )

                    # –ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è (–∫–∞–∂–¥—ã–π –∫–∞–¥—Ä)
                    if results.pose_landmarks:
                        tension_analyzer.analyze_frame(
                            results.pose_landmarks,
                            frame_number
                        )
                        
                        # –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò: 7 –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ç–µ—Ö–Ω–∏–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                        timestamp = frame_number / fps if fps > 0 else frame_number * 0.033
                        
                        # –ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏ (7 –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫)
                        technique_metrics = technique_analyzer.analyze_frame(
                            results.pose_landmarks,
                            frame_number,
                            timestamp,
                            frame_data
                        )
                        overlays.technique_metrics_history.append(technique_metrics)
                        if len(overlays.technique_metrics_history) > 90:
                            overlays.technique_metrics_history.pop(0)
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                        additional_metrics = additional_analyzer.analyze_frame(
                            results.pose_landmarks,
                            frame_number,
                            frame_data,
                            technique_metrics
                        )
                        overlays.additional_metrics_history.append(additional_metrics)
                        if len(overlays.additional_metrics_history) > 90:
                            overlays.additional_metrics_history.pop(0)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º overlays —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                        if overlays.technique_metrics_history:
                            # –ü–µ—Ä–µ–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ overlays –¥–ª—è –ø–∞—É—Ç–∏–Ω–∫–∏
                            latest_technique = overlays.technique_metrics_history[-1]
                            # –û–±–Ω–æ–≤–ª—è–µ–º metrics_history –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                            overlays.metrics_history.append(latest_technique)
                            if len(overlays.metrics_history) > 90:
                                overlays.metrics_history.pop(0)

                    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                    if results.pose_landmarks:
                        frame = overlays.apply_overlay(
                            frame,
                            results.pose_landmarks,
                            output_overlay,
                            frame_data,
                            holds_detector=holds_detector,
                            holds=detected_holds if output_overlay == "holds" else None
                        )
                    else:
                        # –ï—Å–ª–∏ landmarks –Ω–µ—Ç, –≤—Å–µ —Ä–∞–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å None
                        # —á—Ç–æ–±—ã –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ —Ç–µ—Ä—è–ª–∏—Å—å
                        overlays._update_history(None, frame.shape[:2], frame_data)
                    
                    processed_count += 1
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä
                out.write(frame)
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                if progress_callback and frame_number % 30 == 0:
                    progress = int((frame_number / total_frames) * 100)
                    await progress_callback(progress, f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ {frame_number}/{total_frames}")
                
                frame_number += 1
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º
            cap.release()
            out.release()
            
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∫–∞–¥—Ä–æ–≤ –∏–∑ {total_frames}")
            
            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            statistics = frame_analyzer.get_statistics()
            best_worst = frame_analyzer.find_best_worst_frames()
            technical_issues = analyze_technical_issues(frame_analyzer.frame_data)
            
            # BoulderVision —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            bv_summary = bv_metrics.get_summary()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞—Ü–µ–ø–æ–≤
            holds_analysis = {}
            if holds_detector:
                holds_analysis = holds_detector.get_hold_analysis(fps)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV
            csv_path = TEMP_DIR / f"analysis_{video_path.stem}.csv"
            generate_csv_report(frame_analyzer.frame_data, csv_path)

            # ========== –ù–û–í–´–ï –ê–õ–ì–û–†–ò–¢–ú–ò–ß–ï–°–ö–ò–ï –ê–ù–ê–õ–ò–ó–´ ==========

            # 1. –ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è (tension)
            logger.info("–ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è...")
            tension_summary = tension_analyzer.get_summary()

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ video_analysis –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π
            video_analysis_temp = {
                'duration': duration,
                'fps': fps,
                'total_frames': total_frames,
                'avg_pose_quality': statistics.get('avg_pose_quality', 0),
                'avg_motion_intensity': statistics.get('avg_motion_intensity', 0),
                'avg_balance_score': statistics.get('avg_balance_score', 0),
                'fall_detected': fall_detector.fall_detected,
                'bouldervision': bv_summary,
                'tension_analysis': tension_summary
            }

            # 2. –ü—Ä–æ–≥–Ω–æ–∑ —Ç—Ä–∞–≤–º
            logger.info("–ü—Ä–æ–≥–Ω–æ–∑ —Ç—Ä–∞–≤–º...")
            injury_predictions = injury_predictor.predict_injuries(
                tension_summary,
                video_analysis_temp,
                duration
            )

            # 3. Nine-box –º–æ–¥–µ–ª—å
            logger.info("Nine-box –æ—Ü–µ–Ω–∫–∞...")
            nine_box_assessment = nine_box_model.assess_climber(
                video_analysis_temp,
                user_profile={}  # –ü—É—Å—Ç–æ–π –ø—Ä–æ—Ñ–∏–ª—å, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
            )
            
            # 4. –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò: –°–≤–æ–¥–∫–∞ –ø–æ 7 –±–∞–∑–æ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º —Ç–µ—Ö–Ω–∏–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º
            logger.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ç–µ—Ö–Ω–∏–∫–∏...")
            
            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —Ç–µ—Ö–Ω–∏–∫–∏ –∑–∞ –≤—Å—ë –≤–∏–¥–µ–æ
            avg_technique_metrics = {}
            if overlays.technique_metrics_history:
                for metric_name in ['quiet_feet', 'hip_position', 'diagonal', 'route_reading', 'rhythm', 'dynamic_control', 'grip_release']:
                    values = [m.get(metric_name, 50.0) for m in overlays.technique_metrics_history if metric_name in m]
                    if values:
                        avg_technique_metrics[metric_name] = sum(values) / len(values)
                    else:
                        avg_technique_metrics[metric_name] = 50.0
            else:
                # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏
                avg_technique_metrics = {
                    'quiet_feet': 50.0, 'hip_position': 50.0, 'diagonal': 50.0,
                    'route_reading': 50.0, 'rhythm': 50.0, 'dynamic_control': 50.0, 'grip_release': 50.0
                }
            
            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            avg_additional_metrics = {}
            if overlays.additional_metrics_history:
                # –£—Å—Ä–µ–¥–Ω—è–µ–º –í–°–ï 8 –º–µ—Ç—Ä–∏–∫ (–≤–∫–ª—é—á–∞—è productivity, economy, balance)
                for metric_name in ['stability', 'exhaustion', 'arm_efficiency', 'leg_efficiency', 'recovery', 'productivity', 'economy', 'balance']:
                    values = [m.get(metric_name, 50.0) for m in overlays.additional_metrics_history if metric_name in m]
                    if values:
                        avg_additional_metrics[metric_name] = sum(values) / len(values)
                    else:
                        avg_additional_metrics[metric_name] = 50.0
            else:
                avg_additional_metrics = {
                    'stability': 50.0, 'exhaustion': 0.0, 'arm_efficiency': 50.0,
                    'leg_efficiency': 50.0, 'recovery': 50.0,
                    'productivity': 50.0, 'economy': 50.0, 'balance': 50.0
                }
            
            # 5. SWOT-–∞–Ω–∞–ª–∏–∑
            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SWOT-–∞–Ω–∞–ª–∏–∑–∞...")
            swot_analysis = swot_generator.generate_swot(
                avg_technique_metrics,
                avg_additional_metrics,
                tension_summary,
                {
                    'duration': duration,
                    'total_frames': total_frames,
                    'fps': fps
                }
            )
            
            # 6. –û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            estimated_grade = swot_generator.estimate_grade(avg_technique_metrics)
            
            logger.info(f"‚úÖ –í—Å–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã. –û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è: {estimated_grade}")

            # –ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                'processed_video_path': str(output_path),
                'csv_path': str(csv_path),
                'duration': duration,
                'total_frames': total_frames,
                'processed_frames': processed_count,
                'fps': fps,
                
                # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                **statistics,
                'best_frame': best_worst.get('best'),
                'worst_frame': best_worst.get('worst'),
                'technical_issues': technical_issues,
                
                # –ü–∞–¥–µ–Ω–∏–µ
                'fall_detected': fall_detector.fall_detected,
                'fall_frame': fall_detector.fall_frame,
                'fall_timestamp': fall_detector.fall_timestamp,
                'fall_analysis': fall_detector.get_fall_analysis(),
                
                # BoulderVision –º–µ—Ç—Ä–∏–∫–∏
                'bouldervision': {
                    'avg_velocity_ratio': bv_summary.get('avg_velocity_ratio', 1.0),
                    'max_velocity_ratio': bv_summary.get('max_velocity_ratio', 1.0),
                    'min_velocity_ratio': bv_summary.get('min_velocity_ratio', 1.0),
                    'velocity_std': bv_summary.get('velocity_std', 0.0),
                    'total_distance': bv_summary.get('total_distance', 0.0),
                    'avg_frame_distance': bv_summary.get('avg_frame_distance', 0.0),
                    'peak_velocity_frame': bv_summary.get('peak_velocity_frame'),
                    'slowest_frame': bv_summary.get('slowest_frame'),
                    'movement_pattern': bv_summary.get('movement_pattern', 'unknown'),
                    'time_zones': bv_summary.get('time_zones', {'lower':0,'middle':0,'upper':0})
                },

                # ========== –ù–û–í–´–ï –ê–õ–ì–û–†–ò–¢–ú–ò–ß–ï–°–ö–ò–ï –ê–ù–ê–õ–ò–ó–´ ==========

                # –ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è
                'tension_analysis': {
                    'overall_tension_index': tension_summary.get('overall_tension_index', 0),
                    'risk_level': tension_summary.get('risk_level', 'LOW'),
                    'zones': tension_summary.get('zones', {}),
                    'high_tension_moments': tension_summary.get('high_tension_moments', []),
                    'recommendations': tension_summary.get('recommendations', [])
                },

                # –ü—Ä–æ–≥–Ω–æ–∑ —Ç—Ä–∞–≤–º
                'injury_prediction': {
                    'predictions': {
                        injury_type: {
                            'injury_type': pred.injury_type,
                            'body_part': pred.body_part,
                            'probability': pred.probability,
                            'risk_level': pred.risk_level.value,
                            'trauma_type': pred.trauma_type.value,
                            'timeline': pred.timeline,
                            'contributing_factors': pred.contributing_factors,
                            'prevention_measures': pred.prevention_measures,
                            'early_indicators': pred.early_indicators,
                            'self_test': pred.self_test
                        }
                        for injury_type, pred in injury_predictions.items()
                    },
                    'overall_risk': max(
                        [pred.probability for pred in injury_predictions.values()],
                        default=0.0
                    )
                },

                # Nine-box –º–æ–¥–µ–ª—å
                'nine_box': {
                    'skill_score': nine_box_assessment['scores']['skill'],
                    'physical_score': nine_box_assessment['scores']['physical'],
                    'mental_score': nine_box_assessment['scores']['mental'],
                    'category': nine_box_assessment['box_category'],
                    'label': nine_box_assessment['label'],
                    'description': nine_box_assessment['description'],
                    'position': nine_box_assessment['position'],
                    'recommendations': nine_box_assessment['recommendations'],
                    'ascii_plot': nine_box_assessment.get('ascii_plot', '')
                },

                # –ê–Ω–∞–ª–∏–∑ –∑–∞—Ü–µ–ø–æ–≤
                'holds_analysis': holds_analysis,
                
                # ========== –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –¢–ï–•–ù–ò–ö–ò ==========
                'technique_metrics': avg_technique_metrics,
                'additional_metrics': avg_additional_metrics,
                'swot_analysis': swot_analysis,
                'estimated_grade': estimated_grade
            }
            
            # ========== –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–®–ë–û–†–î–ê ==========
            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–∞...")
            try:
                # #region agent log
                with open('/home/user/—Å –≤–∏–Ω–¥—ã/ClimbAI/telegram_bot_bouldervision/.cursor/debug.log', 'a') as f:
                    import json
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"D","location":"processor.py:398","message":"dashboard generation start","data":{},"timestamp":int(__import__('time').time()*1000)})+'\n')
                # #endregion
                from app.reports.dashboard import DashboardGenerator
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ (–ù–û–í–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø)
                dashboard_data = {
                    'duration': duration,
                    'avg_pose_quality': statistics.get('avg_pose_quality', 0),
                    'avg_motion_intensity': statistics.get('avg_motion_intensity', 0),
                    'avg_balance_score': statistics.get('avg_balance_score', 0),
                    'fall_detected': fall_detector.fall_detected,
                    'bouldervision': {
                        'velocity_history': bv_metrics.all_velocity_ratios[:200] if hasattr(bv_metrics, 'all_velocity_ratios') else []
                    },
                    'tension_analysis': {
                        'zones': tension_summary.get('zones', {})
                    },
                    'weight_distribution': {},
                    # –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò
                    'technique_metrics': avg_technique_metrics,
                    'additional_metrics': avg_additional_metrics,
                    'swot_analysis': swot_analysis,
                    'estimated_grade': estimated_grade,
                    # –°—Ç–∞—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    'metrics': avg_technique_metrics  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—ã–µ
                }
                
                dashboard_gen = DashboardGenerator()
                dashboard_path = TEMP_DIR / f"dashboard_{video_path.stem}.png"
                
                # #region agent log
                with open('/home/user/—Å –≤–∏–Ω–¥—ã/ClimbAI/telegram_bot_bouldervision/.cursor/debug.log', 'a') as f:
                    import json
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"D","location":"processor.py:421","message":"dashboard generation before call","data":{"dashboard_path":str(dashboard_path),"has_metrics":bool(dashboard_data.get('metrics'))},"timestamp":int(__import__('time').time()*1000)})+'\n')
                # #endregion
                
                dashboard_gen.generate_dashboard(dashboard_data, dashboard_path, format="png")
                
                # #region agent log
                with open('/home/user/—Å –≤–∏–Ω–¥—ã/ClimbAI/telegram_bot_bouldervision/.cursor/debug.log', 'a') as f:
                    import json
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"D","location":"processor.py:428","message":"dashboard generation success","data":{"dashboard_path":str(dashboard_path),"file_exists":dashboard_path.exists()},"timestamp":int(__import__('time').time()*1000)})+'\n')
                # #endregion
                
                result['dashboard_path'] = str(dashboard_path)
                logger.info(f"‚úÖ –î–∞—à–±–æ—Ä–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {dashboard_path}")
            except Exception as e:
                # #region agent log
                with open('/home/user/—Å –≤–∏–Ω–¥—ã/ClimbAI/telegram_bot_bouldervision/.cursor/debug.log', 'a') as f:
                    import json
                    f.write(json.dumps({"sessionId":"debug-session","runId":"run1","hypothesisId":"D","location":"processor.py:432","message":"dashboard generation error","data":{"error":str(e),"error_type":type(e).__name__},"timestamp":int(__import__('time').time()*1000)})+'\n')
                # #endregion
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞—à–±–æ—Ä–¥: {e}")
                result['dashboard_path'] = None
            
            logger.info("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {e}", exc_info=True)
            raise
        
        finally:
            # –ö–†–ò–¢–ò–ß–ù–û: –í—Å–µ–≥–¥–∞ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã, –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if cap is not None:
                try:
                    cap.release()
                    logger.debug("‚úì VideoCapture released")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å–≤–æ–±–æ–¥–∏—Ç—å VideoCapture: {e}")
            
            if out is not None:
                try:
                    out.release()
                    logger.debug("‚úì VideoWriter released")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å–≤–æ–±–æ–¥–∏—Ç—å VideoWriter: {e}")
            
            if pose is not None:
                try:
                    pose.close()
                    logger.debug("‚úì MediaPipe Pose closed")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫—Ä—ã—Ç—å MediaPipe Pose: {e}")
    
    def get_available_overlays(self) -> Dict[str, str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        
        Returns:
            dict —Å –∫–ª—é—á–∞–º–∏-–∫–æ–¥–∞–º–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏-–æ–ø–∏—Å–∞–Ω–∏—è–º–∏
        """
        overlays = {
            # –ë–∞–∑–æ–≤—ã–µ (1-5)
            'skeleton': 'ü¶¥ –°–∫–µ–ª–µ—Ç - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è',
            'points': 'üéØ –¢–æ—á–∫–∏ - —Ü–≤–µ—Ç–æ–≤–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —á–∞—Å—Ç–µ–π —Ç–µ–ª–∞',
            'stress': 'üî• –ù–∞–ø—Ä—è–∂–µ–Ω–∏–µ - –∞–Ω–∞–ª–∏–∑ —É–≥–ª–æ–≤ —Å—É—Å—Ç–∞–≤–æ–≤',
            'center': 'üìç –¶–µ–Ω—Ç—Ä –º–∞—Å—Å - —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏—è',
            'metrics': 'üìä –ú–µ—Ç—Ä–∏–∫–∏ - —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –Ω–∞ –≤–∏–¥–µ–æ',

            # BoulderVision (6-8)
            'heatmap': 'üå°Ô∏è –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ - –∑–æ–Ω—ã –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏',
            'trajectory': 'üìà –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è - –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è',
        }

        # –î–æ–±–∞–≤–ª—è–µ–º holds —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä
        if self.holds_detector and self.holds_detector.is_initialized:
            overlays['holds'] = 'üéØ –ó–∞—Ü–µ–ø—ã - –¥–µ—Ç–µ–∫—Ü–∏—è –∏ —Å–≤—è–∑–∏ —Å –∫–æ–Ω–µ—á–Ω–æ—Å—Ç—è–º–∏'
        else:
            overlays['holds'] = 'üéØ –ó–∞—Ü–µ–ø—ã (—Ç—Ä–µ–±—É–µ—Ç—Å—è ROBOFLOW_API_KEY)'

        # Wow-Effect –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (9-12)
        overlays.update({
            'force_fingerprint': 'üí™ –°–∏–ª–æ–≤–æ–π –æ—Ç–ø–µ—á–∞—Ç–æ–∫ - –ø–æ–ª—è—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏',
            'decision_map': 'üß† –ö–∞—Ä—Ç–∞ —Ä–µ—à–µ–Ω–∏–π - –º–æ–º–µ–Ω—Ç—ã —Ä–∞–∑–¥—É–º–∏–π –Ω–∞ —Ç—Ä–∞—Å—Å–µ',
            'energy_profile': 'üîã –ü—Ä–æ—Ñ–∏–ª—å —ç–Ω–µ—Ä–≥–∏–∏ - –∏—Å—Ç–æ—â–µ–Ω–∏–µ —Å–∏–ª –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏',
            'ghost_comparison': 'üëª –ü—Ä–∏–∑—Ä–∞–∫ - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª—É—á—à–µ–π –ø–æ–ø—ã—Ç–∫–æ–π',
        })
        
        return overlays
